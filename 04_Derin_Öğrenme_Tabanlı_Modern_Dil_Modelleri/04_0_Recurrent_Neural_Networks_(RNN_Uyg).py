# =============================================
# ğŸ“Š RNN ile Duygu Analizi (Sentiment Analysis)
# Yorum verilerini kullanarak pozitif/negatif sÄ±nÄ±flandÄ±rma
# =============================================
"""
Problem ve tanÄ±mÄ±:
    Duygu analizi -> Sentiment Analysis
    Bir cumlenin etiketlenmesi
    (positive ve negatif)
    
    Yani sÄ±nÄ±flandÄ±rma
    Solve Classification problem (sentiment Analysis in NLP)
    with RNN (Deep learning based Language Model)

    Restoran mÃ¼ÅŸteri yorumlarÄ± degerlendirme

"""

# import libraries
import numpy as np
import pandas as pd

from gensim.models import Word2Vec  # metin temsili iÃ§in

from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Embedding

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder


# create dataset
data = {
    "text": [
        "Yemekler harikaydÄ±, her ÅŸey taze ve lezzetliydi.",
        "Garson Ã§ok ilgisizdi, sipariÅŸimi unuttular.",
        "TatlÄ±lar gerÃ§ekten Ã§ok gÃ¼zeldi, bayÄ±ldÄ±m!",
        "Yemekler soÄŸuktu ve tadÄ± hiÃ§ hoÅŸ deÄŸildi.",
        "Atmosfer oldukÃ§a keyifliydi, tekrar geleceÄŸim.",
        "Fiyatlar biraz yÃ¼ksekti ama yemekler gÃ¼zeldi.",
        "Servis kalitesi Ã§ok iyiydi, teÅŸekkÃ¼rler.",
        "Yemek Ã§ok geÃ§ geldi, sabrÄ±m kalmadÄ±.",
        "Lezzetli bir akÅŸam yemeÄŸi deneyimledik.",
        "Bu restoranÄ± asla tavsiye etmem, kÃ¶tÃ¼ydÃ¼.",
        "Mekan Ã§ok hoÅŸtu, Ã¶zellikle dekorasyonu.",
        "Yemekler beklediÄŸimden Ã§ok daha kÃ¶tÃ¼ydÃ¼.",
        "GÃ¼zel bir akÅŸam geÃ§irdik, teÅŸekkÃ¼rler.",
        "Yemekler fazlasÄ±yla tuzlu geldi, hiÃ§ beÄŸenmedim.",
        "KahvaltÄ± muhteÅŸemdi, her ÅŸeyi denemek istedim.",
        "Fiyatlar oldukÃ§a makuldÃ¼, Ã§ok memnun kaldÄ±m.",
        "Garsonlar Ã§ok yardÄ±mseverdi, teÅŸekkÃ¼rler.",
        "Yemekler gÃ¼zel ama servis biraz yavaÅŸtÄ±.",
        "Ã‡ocuklar iÃ§in harika bir yer, Ã§ok eÄŸlendiler.",
        "Bir daha asla gitmeyeceÄŸim, kÃ¶tÃ¼ bir deneyim yaÅŸadÄ±m.",
        "MekanÄ±n atmosferi Ã§ok keyifliydi.",
        "Yemeklerin tadÄ± harikaydÄ±, Ã¶zellikle deniz Ã¼rÃ¼nleri.",
        "Åarap menÃ¼sÃ¼ oldukÃ§a zengindi, beÄŸendim.",
        "Yemekler sÄ±cak servis edilmedi, hayal kÄ±rÄ±klÄ±ÄŸÄ±ydÄ±.",
        "Burgerleri gerÃ§ekten Ã§ok lezzetliydi.",
        "TatlÄ±larÄ±n fiyatÄ± biraz yÃ¼ksekti ama lezzetliydi.",
        "Hizmet Ã§ok yavaÅŸtÄ± ama yemekler fena deÄŸildi.",
        "GerÃ§ekten gÃ¼zel bir akÅŸam yemeÄŸi deneyimi yaÅŸadÄ±k.",
        "Sushi taze ve lezzetliydi, kesinlikle tavsiye ederim.",
        "Garsonlar Ã§ok nazik ve yardÄ±mseverdi.",
        "Hizmetin daha iyi olmasÄ±nÄ± beklerdim.",
        "KahvaltÄ± menÃ¼sÃ¼ oldukÃ§a zengindi, Ã§ok beÄŸendim.",
        "Yemekler Ã§ok lezzetliydi ama servis biraz yavaÅŸtÄ±.",
        "Fiyatlar oldukÃ§a makuldÃ¼, bu kadar iyi hizmete.",
        "Mekan Ã§ok temizdi, bu benim iÃ§in Ã¶nemli.",
        "TatlÄ±larÄ±n Ã§ok ÅŸekerli olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼m.",
        "Hizmet yavaÅŸ ama mekan gÃ¼zeldi.",
        "Yemeklerin lezzeti harikaydÄ± ama porsiyonlar kÃ¼Ã§Ã¼k.",
        "Kendimi Ã§ok Ã¶zel hissettim, teÅŸekkÃ¼rler.",
        "GÃ¼zel bir akÅŸam yemeÄŸi, tekrar geleceÄŸim.",
        "Ã‡alÄ±ÅŸanlar Ã§ok gÃ¼ler yÃ¼zlÃ¼ydÃ¼.",
        "Pasta Ã§ok gÃ¼zeldi, Ã¶zellikle Ã§ikolatalÄ±.",
        "Biraz beklemek zorunda kaldÄ±k ama deÄŸdi.",
        "Sadece fiyatlar biraz yÃ¼ksekti ama lezzet buna deÄŸer.",
        "Mekan oldukÃ§a kalabalÄ±ktÄ± ama hizmet gÃ¼zel.",
        "Garsonlar Ã§ok nazik ama biraz daha hÄ±zlÄ± olabilirdi.",
        "Yemeklerin sunumu gerÃ§ekten etkileyiciydi.",
        "Yemekler Ã§ok lezzetliydi ama garsonlar nazik deÄŸildi.",
        "Ã‡ok gÃ¼zel bir akÅŸam yemeÄŸi deneyimi yaÅŸadÄ±m.",
        "Pasta sipariÅŸi verdim ama Ã§ok uzun sÃ¼rdÃ¼."
    ],
    "label": [
        "positive", "negative", "positive", "negative", "positive",
        "positive", "positive", "negative", "positive", "negative",
        "positive", "negative", "positive", "negative", "positive",
        "positive", "positive", "positive", "negative", "negative",
        "positive", "positive", "positive", "negative", "positive",
        "negative", "positive", "positive", "positive", "positive",
        "negative", "positive", "positive", "negative", "negative",
        "negative", "positive", "positive", "positive", "positive",
        "positive", "positive", "positive", "positive", "negative",
        "negative", "positive", "positive", "positive", "negative"

    ]
}

df = pd.DataFrame(data)


# %% metin temizleme ve propecessing:
# tokenization, padding, label encoding , train test split


# tokenization
# Tokenizer: kelimelere sayÄ± atamasÄ± yapar ve dizilere Ã§evirir
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df["text"])
sequences = tokenizer.texts_to_sequences(df["text"])
word_index = tokenizer.word_index

# padding process
# padding: bizim cÃ¼mlelerimiz iÃ§erisinde kelime sayÄ±lari farklÄ±
# bizim bunlarÄ± fixlememiz lazÄ±m ondan padding kullanÄ±yoruz
# Padding: tÃ¼m cÃ¼mleleri eÅŸit uzunluÄŸa getiriyoruz
maxlen = max(len(seq) for seq in sequences)
X = pad_sequences(sequences = sequences, maxlen = maxlen )
print(X.shape)


# Label encoding: pozitif/negatif -> 1/0
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(df["label"])
# y de ki 1 ve 0 pozitif egatif karÅŸÄ±lÄ±k gelir 


# train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Ã§ok az oldu Ã§Ã¼nkÃ¼ veri 50 satÄ±r Ã§ok az fazla olmasÄ± lazim normalde


# %% metin temsili : word embedding: word2vec

sentences = [text.split() for text in df["text"]]
word2vec_model = Word2Vec(sentences, vector_size=50, window=5, min_count=1)
# UYARIIII dataframe text kullanarak aslÄ±nda cÃ¼mlelermizi elde ediyoruz
# split ediyoruz sonrasÄ±nda word index ile eÅŸeltirityoruz
# burada doÄŸrudan wordindex kullanarak da yapabilirdik ama
# df kullanarak tokenlaÅŸtÄ±rarak word_index ile eÅŸleÅŸtirip
# embedding matrisinimizi oluÅŸtuyorujz


# burada ne yapÄ±yporuz: burada eÄŸitim sÄ±rasÄ±nda olusturunaÅŸ
# word vektÃ¶rÃ¼nÃ¼n kelime modelleri gÃ¶mme matrisine ekleniyor
# embedding matrisine bu iÅŸlem kelimeleri sayÄ±sal biÃ§imde 
# temsil etmek iÃ§in yaoÄŸtÄ±mÄ±z bir iÅŸlem Ã¶ncelikle burada ji word index
# isimli bir deÄŸiÅŸken kullanarak her kelimenin sÄ±ralÄ± indexi belirlenip
# model de oluÄŸ olmadÄ±ÄŸÄ± kontrol edilip ekleniyor 
# Girdi katmanÄ±: Ã¶nceden eÄŸitilmiÅŸ embedding matrisi ile
embedding_dim = 50
embedding_matrix = np.zeros((len(word_index) + 1 , embedding_dim))
for word, i in word_index.items():
    if word in word2vec_model.wv:
        embedding_matrix[i] = word2vec_model.wv[word]

# %% modelling: build, traing ve test rnn modeli

# build model 
model = Sequential()

# embedding
model.add(Embedding(input_dim= len(word_index)+1, 
                    output_dim= embedding_dim,
                    weights= [embedding_matrix],
                    input_length= maxlen,
                    trainable = False   
                    ))

# RNN layer
model.add(SimpleRNN(50, return_sequences=False))


# output layer
model.add(Dense(1, activation="sigmoid"))


# complie model
model.compile(optimizer= "adam", loss = "binary_crossentropy", metrics= ["accuracy"])


# train model
model.fit(X_train, y_train, epochs=10, batch_size=2, validation_data=(X_test,y_test))


# evaluate rnn model
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")



# %% cumle siniflandirma calismasi
# sanki daha Ã¶ncesinde bir app varmÄ±ÅŸda 
# birileri yorumlarÄ± yuklemis bizim
# algortimamÄ±zda bu yourumlarÄ± degerlendirecekmiÅŸ gibi
def classify_sentence(sentence):
    seq = tokenizer.texts_to_sequences([sentence])
    padded_seq = pad_sequences(seq, maxlen= maxlen)
    
    prediction = model.predict(padded_seq)
    
    predicted_class = (prediction > 0.5).astype(int)
    label = "positive" if predicted_class[0][0] == 1 else "negative"
    
    return prediction,label

sentence = "Restaurant Ã§ok temizdi ve yemekler Ã§ok gÃ¼zeldi, beÄŸendik gÃ¼zel"

result = classify_sentence(sentence)
print(f"Result: {result}")



"""
    Ã–dev
Data boyutunu arttÄ±r
E-ticaret Ã¼rÃ¼n Ã¶rneÄŸi gibi
epoch sayÄ±sÄ± deÄŸiÅŸtir
Veri boyutunu artÄ±r (Ã¶rn. 500+ yorum)
Stop-words temizliÄŸi ve lemmatization ekle
Daha karmaÅŸÄ±k modeller (LSTM, Bidirectional RNN, Attention)
Modeli kaydet & Flask ile servis et
"""

