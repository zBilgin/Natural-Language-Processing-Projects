
# =============================================
# ğŸ§  Word2Vec + KMeans + PCA: Kelime KÃ¼meleme ve 2D GÃ¶rselleÅŸtirme (IMDB Dataset)
# =============================================

# ğŸ“¦ Gerekli KÃ¼tÃ¼phaneler
import pandas as pd
import matplotlib.pyplot as plt
import re

from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

from gensim.models import Word2Vec
from gensim.utils import simple_preprocess

# =============================================
# ğŸ“¥ Veri Seti YÃ¼kleme

# IMDB film yorumlarÄ±nÄ± iÃ§eren veri setini oku
# "review" sÃ¼tunu pozitif/negatif film yorumlarÄ± iÃ§eriyor
df = pd.read_csv("Datasets/IMDB_Dataset.csv")
documents = df["review"]

# =============================================
# ğŸ§¼ Veri Temizleme Fonksiyonu

def clean_text(text):
    text = text.lower()  # KÃ¼Ã§Ã¼k harfe Ã§evir
    text = re.sub(r"\d+", "", text)  # SayÄ±larÄ± kaldÄ±r
    text = re.sub(r"[^\w\s]", "", text)  # Noktalama ve Ã¶zel karakterleri kaldÄ±r
    text = " ".join([word for word in text.split() if len(word) > 2])  # KÄ±sa anlamsÄ±z kelimeleri Ã§Ä±kar
    #text = simple_preprocess(text)
    return text

# Ã–rnek test
# clean_text("ASDASD 1551 %& I merhabA")

# TÃ¼m belgeleri temizle
cleaned_documents = [clean_text(doc) for doc in documents]

# =============================================
# ğŸ”¤ Tokenizasyon Ä°ÅŸlemi

# Gensim'in simple_preprocess fonksiyonu kullanÄ±larak her cÃ¼mleyi kelimelere ayÄ±r
# Bu adÄ±m clean_text() iÃ§ine de gÃ¶mÃ¼lebilirdi ama eÄŸitimsel amaÃ§la ayrÄ± tutuldu
#tokenize etmeyi clean_text fonk icinde de yapabilirdik yukarÄ±da ki 
#fonk icinde ki yorum satÄ±rÄ± gibi
# neden boyle yapmadÄ±k veri temizleme ve prpeocesing tokenization
# islemini ayrÄ± yapmak gÃ¶rmek icin

tokenized_documents = [simple_preprocess(doc) for doc in cleaned_documents]

# =============================================
# ğŸ§  Word2Vec Modeli EÄŸitimi

model = Word2Vec(
    sentences=tokenized_documents,
    vector_size=50,  # Her kelimeyi 50 boyutlu vektÃ¶rle temsil et
    window=5,        # BaÄŸlam penceresi: saÄŸ-sol 5 kelime
    min_count=1,     # En az 1 kez geÃ§en kelimeleri al
    sg=0             # CBOW (0), sg=1 olursa Skip-Gram
)

#burada vectorsize Ã¶nemli bir parametre
# vector size 2 alÄ±rsak pca boyut indirgemsi gerek kalmaz
# zaten bize 2 li boyutta bir ayrÄ±m verir 

word_vectors = model.wv  # EÄŸitim sonrasÄ± kelime vektÃ¶rlerine eriÅŸim

# Ä°lk 500 kelimeyi al (gÃ¶rselleÅŸtirme iÃ§in yeterli)
words = list(word_vectors.index_to_key)[:500]
vectors = [word_vectors[word] for word in words]  # VektÃ¶r deÄŸerleri

# =============================================
# ğŸ”— KMeans ile KÃ¼meleme

kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(vectors)
clusters = kmeans.labels_  # Her kelime iÃ§in kÃ¼me etiketi (0 veya 1)

# =============================================
# ğŸ“‰ PCA ile Boyut Ä°ndirgeme (50 â†’ 2)

pca = PCA(n_components=2)
reduced_vectors = pca.fit_transform(vectors)  # 2 boyutlu hale getir

# =============================================
# ğŸ“Š 2D GÃ¶rselleÅŸtirme

plt.figure(figsize=(12, 8))
plt.scatter(
    reduced_vectors[:, 0], reduced_vectors[:, 1],
    c=clusters,
    cmap="viridis",
    s=30
)

# KÃ¼melerin merkezlerini iÅŸaretle
centers = pca.transform(kmeans.cluster_centers_)
plt.scatter(
    centers[:, 0], centers[:, 1],
    c="red",
    marker="x",
    s=150,
    label="Cluster Centers"
)
plt.legend()

# Her noktanÄ±n Ã¼stÃ¼ne kelime etiketlerini ekle
for i, word in enumerate(words):
    plt.text(reduced_vectors[i, 0], reduced_vectors[i, 1], word, fontsize=7)

plt.title("Word2Vec + KMeans Clustering (2D PCA)")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.grid(True)
plt.show()

# =============================================
# ğŸ“ Notlar
# - AslÄ±nda Word2Vec vektÃ¶rleri 50 boyutlu, ancak biz PCA ile 2 boyuta indiriyoruz.
# - KÃ¼meleme 50 boyutta yapÄ±lÄ±r, ardÄ±ndan bu sonuÃ§lar 2D'ye indirgenir.
# - Bu nedenle iÃ§ iÃ§e geÃ§miÅŸ gibi gÃ¶rÃ¼nse de, yÃ¼ksek boyutlu uzayda farklÄ± olabilirler.

# âœ… Ã–dev Ã–nerileri:
# - Stop words (gereksiz kelimeler) temizlenerek daha anlamlÄ± sonuÃ§lar alÄ±nabilir.
# - K (kÃ¼me sayÄ±sÄ±) farklÄ± deÄŸerlerde denenebilir (Ã¶rn. K=3, K=5).
# - Word2Vec parametreleri (vector_size, window, sg) deÄŸiÅŸtirilip etkisi gÃ¶zlemlenebilir.
